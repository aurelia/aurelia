version: 2.1

orbs:
  browser-tools: circleci/browser-tools@1.4.7

# # # # # # # # # # # # # # # #
# - Scalar variables -
# # # # # # # # # # # # # # # #
scalar-1: &working_dir ~/repo

# # # # # # # # # # # # # # # #
# - Map variables -
# # # # # # # # # # # # # # # #
map-1: &filter_only_master
  filters:
    branches:
      only:
        - master
    tags:
      ignore: /.*/

map-2: &filter_only_topic
  filters:
    branches:
      ignore:
        - master
        - develop
        - release
    tags:
      ignore: /.*/

parameters:
  run_pr_full:
    type: boolean
    default: false
  run_bench:
    type: boolean
    default: false
  run_pr_lite:
    type: boolean
    default: true

# # # # # # # # # # # # # # # #
# - Executors -
# # # # # # # # # # # # # # # #
executors:
  docker_circleci:
    parameters:
      node:
        type: string
        default: "22.12.0"
    working_directory: *working_dir
    resource_class: large
    docker:
      - image: "cimg/node:<< parameters.node >>-browsers"

  docker_circleci_bench:
    working_directory: *working_dir
    resource_class: large
    docker:
      - image: "cimg/node:22.12.0-browsers"

# # # # # # # # # # # # # # # #
# - Commands -
# # # # # # # # # # # # # # # #
commands:
  setup_verdaccio:
    parameters:
      email:
        type: string
        default: "aurelia@bluespire.com"
      username:
        type: string
        default: "aureliaeffect"
      password:
        type: string
        default: "aurelia"
      registry:
        type: string
        default: "http://localhost:4873"
    steps:
      - run: sudo npm i -g verdaccio npm-cli-login
      - run:
          name: "verdaccio"
          background: true
          command: verdaccio
      - run: npm-cli-login -u <<parameters.username>> -p <<parameters.password>> -e <<parameters.email>> -r <<parameters.registry>>

  checkout_install:
    parameters:
      install:
        type: boolean
        default: true
      install_drivers:
        type: boolean
        default: true
      install_chrome:
        type: boolean
        default: true
      install_firefox:
        type: boolean
        default: true
    steps:
      - checkout
      - when:
          condition:
            and:
              - <<parameters.install_drivers>>
              - <<parameters.install_chrome>>
          steps:
            - browser-tools/install-chrome
            - browser-tools/install-chromedriver
      - when:
          condition:
            and:
              - <<parameters.install_drivers>>
              - <<parameters.install_firefox>>
          steps:
            - browser-tools/install-firefox
            - browser-tools/install-geckodriver
      - when:
          condition: <<parameters.install>>
          steps:
            - run: npm ci

  checkout_install_build_bundle_publish_verdaccio:
    parameters:
      channel:
        type: string
      suffix:
        type: string
        default: ""
      registry:
        type: string
        default: "http://localhost:4873"
    steps:
      - checkout
      - restore_cache:
          key: cache-{{ checksum "package-lock.json" }}-install
      - restore_cache:
          name: "Restore build artifacts"
          key: cache-{{ .Revision }}-build-true
      - run: npm run generate-native-modules
      - run: npm run bump-version:<< parameters.channel >> -- << parameters.suffix >>
      - setup_verdaccio
      - run: npm config set registry << parameters.registry >>
      - run: npm run publish:<< parameters.channel >>

# # # # # # # # # # # # # # # #
# - Jobs -
# # # # # # # # # # # # # # # #
jobs:
  checkout_install_cache:
    executor: docker_circleci
    steps:
      - checkout
      - restore_cache:
          key: cache-{{ checksum "package-lock.json" }}-install
      - run: |
          # cache restored
          if [[ $(ls -l node_modules | grep -c ^d) -gt 10 ]]; then
            exit 0
          else
            npm ci
          fi
      - save_cache:
          key: cache-{{ checksum "package-lock.json" }}-install
          paths:
            - node_modules
            - packages/__tests__/node_modules

            - packages-tooling/__tests__/node_modules
            - packages-tooling/au/node_modules
            - packages-tooling/babel-jest/node_modules
            - packages-tooling/http-server/node_modules
            - packages-tooling/parcel-transformer/node_modules
            - packages-tooling/plugin-conventions/node_modules
            - packages-tooling/plugin-gulp/node_modules
            - packages-tooling/ts-jest/node_modules
            - packages-tooling/vite-plugin/node_modules
            - packages-tooling/webpack-loader/node_modules

  build_and_cache:
    executor: docker_circleci
    parameters:
      command:
        type: string
        default: npm run build
      release:
        type: boolean
        default: false
      generate_native_modules:
        type: boolean
        default: false
    steps:
      - checkout
      - restore_cache:
          key: cache-{{ checksum "package-lock.json" }}-install
      - when:
          condition:
            equal: [true, << parameters.release >>]
          steps:
            - run: npm run build:release
      - when:
          condition:
            equal: [false, << parameters.release >>]
          steps:
            - run: npm run build
      - when:
          condition:
            equal: [false, << parameters.release >>]
          steps:
            - run: << parameters.command >>
      - when:
          condition: << parameters.generate_native_modules >>
          steps:
            - run: npm run generate-native-modules
      - save_cache:
          key: cache-{{ .Revision }}-build-<< parameters.release >>
          paths:
            - packages/__tests__/dist
            - packages/addons/dist
            - packages/aurelia/dist
            - packages/compat-v1/dist
            - packages/dialog/dist
            - packages/fetch-client/dist
            - packages/i18n/dist
            - packages/kernel/dist
            - packages/metadata/dist
            - packages/platform/dist
            - packages/platform-browser/dist
            - packages/route-recognizer/dist
            - packages/router-direct/dist
            - packages/router/dist
            - packages/expression-parser/dist
            - packages/runtime/dist
            - packages/template-compiler/dist
            - packages/runtime-html/dist
            - packages/state/dist
            - packages/store-v1/dist
            - packages/testing/dist
            - packages/ui-virtualization/dist
            - packages/validation/dist
            - packages/validation-html/dist
            - packages/validation-i18n/dist
            - packages/web-components/dist

            - packages-tooling/__tests__/dist
            - packages-tooling/au/dist
            - packages-tooling/babel-jest/dist
            - packages-tooling/http-server/dist
            - packages-tooling/parcel-transformer/dist
            - packages-tooling/plugin-conventions/dist
            - packages-tooling/plugin-gulp/dist
            - packages-tooling/ts-jest/dist
            - packages-tooling/vite-plugin/dist
            - packages-tooling/webpack-loader/dist

  unit_test_esm:
    parameters:
      coverage:
        type: boolean
        default: true
      npm_command:
        type: string
        default: "test"
      install_chrome:
        type: boolean
        default: false
      install_firefox:
        type: boolean
        default: false
    executor: docker_circleci
    parallelism: 4
    steps:
      - checkout_install:
          install_chrome: <<parameters.install_chrome>>
          install_firefox: <<parameters.install_firefox>>
          install: false
      - restore_cache:
          key: cache-{{ checksum "package-lock.json" }}-install
      - restore_cache:
          key: cache-{{ .Revision }}-build-true
      - run:
          name: "Split test glob"
          command: |
            echo $(circleci tests glob "packages/__tests__/dist/**/*.spec.js" | circleci tests split --split-by=name)
            echo $(circleci tests glob "packages/__tests__/dist/**/*.spec.js" | circleci tests split --split-by=name) > packages/__tests__/tests.txt
      - run:
          name: "Run unit tests"
          command: |
            cd packages/__tests__
            npm run << parameters.npm_command >>
          no_output_timeout: "5m"
      - when:
          condition: << parameters.coverage >>
          steps:
            - run:
                name: "Process coverage for Codecov"
                command: |
                  node_modules/codecov/bin/codecov -f packages/__tests__/coverage/coverage-final.json

  unit_test_esm_node:
    executor: docker_circleci
    parallelism: 4
    steps:
      - checkout_install:
          install_chrome: false
          install_firefox: false
          install: false
      - restore_cache:
          name: "Restore dependencies"
          key: cache-{{ checksum "package-lock.json" }}-install
      - restore_cache:
          name: "Restore build artifacts"
          key: cache-{{ .Revision }}-build-true
      - run:
          name: "Split test glob"
          command: |
            cd packages/__tests__
            echo $(circleci tests glob "dist/**/*.spec.js" | circleci tests split --split-by=timings)
            echo $(circleci tests glob "dist/**/*.spec.js" | circleci tests split --split-by=timings) > tests.txt
      - run:
          name: "Run unit tests"
          command: |
            cd packages/__tests__
            npm run ::mocha -- $(cat tests.txt)
          no_output_timeout: "1m"

  unit_test_cjs:
    parameters:
      submodules:
        type: boolean
        default: false
    executor: docker_circleci
    parallelism: 10
    steps:
      - checkout_install:
          install_chrome: false
          install_firefox: false
          install: false
      - restore_cache:
          name: "Restore dependencies"
          key: cache-{{ checksum "package-lock.json" }}-install
      - restore_cache:
          name: "Restore build artifacts"
          key: cache-{{ .Revision }}-build-true
      - when:
          condition: << parameters.submodules >>
          steps:
            - run:
                name: "Pull Submodules"
                command: |
                  git submodule init
                  git submodule update --remote
      - run:
          name: "Split test glob"
          command: |
            cd packages-tooling/__tests__
            echo $(circleci tests glob "dist/**/*.spec.js" | circleci tests split --split-by=timings --timings-type=testname)
            echo $(circleci tests glob "dist/**/*.spec.js" | circleci tests split --split-by=timings --timings-type=testname) > tests.txt
      - run:
          name: "Run unit tests"
          command: |
            cd packages-tooling/__tests__
            npm run ::mocha -- $(cat tests.txt)
          no_output_timeout: "10m"

  lint_packages:
    executor: docker_circleci
    steps:
      - checkout_install:
          install_drivers: false
          install: false
      - restore_cache:
          name: "Restore dependencies"
          key: cache-{{ checksum "package-lock.json" }}-install
      - run: npm run lint:ci
      - run: npm run lint:other:ci

  # e2e hmr
  e2e_test:
    executor: docker_circleci
    parameters:
      path:
        type: string
      run_webpack:
        type: boolean
        default: false
    steps:
      - checkout_install:
          install_drivers: false
          install: false
      - restore_cache:
          name: "Restore dependencies"
          key: cache-{{ checksum "package-lock.json" }}-install
      - restore_cache:
          name: "Restore build artifacts"
          key: cache-{{ .Revision }}-build-true
      - run:
          name: "Run e2e script"
          working_directory: << parameters.path >>
          command: |
            npx playwright install chromium
            npm run test
          no_output_timeout: "1m"
      - when:
          condition: << parameters.run_webpack >>
          steps:
            - run:
                name: "Run e2e webpack"
                working_directory: << parameters.path >>
                command: |
                  npm run test:e2e:webpack
                no_output_timeout: "1m"

  # Standalone playwright test jobs
  e2e_verdaccio:
    executor: docker_circleci
    parameters:
      path:
        type: string
      suite:
        type: string
        default: "examples"
      use_verdaccio:
        type: boolean
        default: true
      registry:
        type: string
        default: "http://localhost:4873"
    steps:
      - checkout_install_build_bundle_publish_verdaccio:
          channel: dev
          suffix: "-${CIRCLE_BUILD_NUM}"
      - when:
          condition: << parameters.use_verdaccio >>
          steps:
            - run:
                name: "Install app via verdaccio"
                command: |
                  cd << parameters.path >>
                  npm i --registry << parameters.registry >>
      - unless:
          condition: << parameters.use_verdaccio >>
          steps:
            - run:
                name: "Install app via npm"
                command: |
                  cd << parameters.path >>
                  npm i
      - run:
          name: "Build test app"
          command: |
            npx rimraf --glob node_modules
            cd << parameters.path >>
            npm run test
          no_output_timeout: "30s"

  tacho_benchmark_prep:
    executor: docker_circleci_bench
    steps:
      - checkout
      - restore_cache:
          name: "Restore dependencies"
          key: cache-{{ checksum "package-lock.json" }}-install
      - restore_cache:
          name: "Restore build artifacts"
          key: cache-{{ .Revision }}-build-true
      - run:
          name: "bench prep dep"
          working_directory: "benchmarks/latest"
          command: npm i
      - run:
          name: "bench prep build"
          working_directory: "benchmarks"
          command: npm run build
      - save_cache:
          key: cache-{{ .Revision }}-benchmark-app
          paths:
            - benchmarks/app-repeat-ce/dist
            - benchmarks/app-repeat-view/dist
            - benchmarks/app-repeat-view-big-template/dist
            - benchmarks/app-repeat-view-keyed-expr/dist
            - benchmarks/app-repeat-view-keyed-string/dist

  tacho_benchmark:
    executor: docker_circleci_bench
    parameters:
      command:
        type: string
    steps:
      - checkout
      - browser-tools/install-chrome
      - browser-tools/install-chromedriver
      - restore_cache:
          name: "Restore dependencies"
          key: cache-{{ checksum "package-lock.json" }}-install
      - restore_cache:
          name: "Restore build artifacts"
          key: cache-{{ .Revision }}-build-true
      - restore_cache:
          name: "Restore benchmark artifacts"
          key: cache-{{ .Revision }}-benchmark-app
      - run:
          name: "benchmark: <<parameters.command>>"
          command: <<parameters.command>>
          working_directory: "benchmarks"
          no_output_timeout: "30s"

  # on branches that only touches doc
  # there's no need to run the workflow
  check_doc_abort:
    executor: docker_circleci
    environment:
      COMMIT_RANGE: << pipeline.git.base_revision >>..<<pipeline.git.revision>>
    steps:
      - checkout
      - run: |
          # Extract commit range (or single commit)
          echo "commit range from CircleCI: ${COMMIT_RANGE}"

          if [[ -n ${CIRCLE_PR_NUMBER} ]]; then
            curl -L "https://github.com/stedolan/jq/releases/download/jq-1.5/jq-linux64" \
              -o jq
            chmod +x jq

            url="https://api.github.com/repos/${CIRCLE_PROJECT_USERNAME}/${CIRCLE_PROJECT_REPONAME}/pulls/${CIRCLE_PR_NUMBER}"
            echo "Querying GitHub: $url"

            if [[ -n "${GITHUB_TOKEN}" ]]; then
              TARGET_BRANCH=$(curl -H "Authorization: token ${GITHUB_TOKEN}" -H "User-Agent: circleci" "${url}" | ./jq '.base.ref' | tr -d '"')
            else
              TARGET_BRANCH=$(curl -H "User-Agent: circleci" "${url}" | ./jq '.base.ref' | tr -d '"')
            fi

            echo "Target branch: ${TARGET_BRANCH}"
            COMMIT_RANGE="${CIRCLE_SHA1}..${TARGET_BRANCH}"
          fi

          echo "Normalized commit range: $COMMIT_RANGE"

          echo "File changed count: $(git diff --name-only $COMMIT_RANGE | grep -v '*' -c)"
          echo "Non doc file changes: $(git diff --name-only $COMMIT_RANGE | grep -v '^doc' -c)"

          if [[ $(git diff --name-only $COMMIT_RANGE | grep -v '*' -c) -gt 0 ]] && [[ $(git diff --name-only $COMMIT_RANGE | grep -v '^doc' -c) -eq 0 ]]; then
            echo "There is only doc work, cancelling workflow $CIRCLE_WORKFLOW_ID ..."
            curl --request POST \
              --url "https://circleci.com/api/v2/workflow/$CIRCLE_WORKFLOW_ID/cancel?circle-token=$CIRCLE_API_TOKEN"
          else
            echo "There are more than doc changes, running workflow $CIRCLE_WORKFLOW_ID..."
          fi

# # # # # # # # # # # # # # # #
# - Workflows -
# # # # # # # # # # # # # # # #
workflows:
  pr_lite:
    # Fast workflow for PR branches
    when: << pipeline.parameters.run_pr_lite >>
    jobs:
      - check_doc_abort:
          <<: *filter_only_topic
          name: pr_lite_check_doc

      - checkout_install_cache:
          <<: *filter_only_topic
          name: pr_lite_install
          requires:
            - pr_lite_check_doc

      - build_and_cache:
          <<: *filter_only_topic
          name: pr_lite_build
          release: true
          requires:
            - pr_lite_install

      - unit_test_esm:
          <<: *filter_only_topic
          name: pr_lite_test_esm
          npm_command: "test-chrome"
          install_chrome: true
          requires:
            - pr_lite_build

      - unit_test_esm_node:
          <<: *filter_only_topic
          name: pr_lite_test_node
          requires:
            - pr_lite_build

      - e2e_test:
          <<: *filter_only_topic
          name: pr_lite_e2e_smoke_vite
          path: "packages/__e2e__/1-gh-issues"
          requires:
            - pr_lite_build

  pr_full:
    when: << pipeline.parameters.run_pr_full >>
    jobs:
      - checkout_install_cache:
          <<: *filter_only_topic
          name: pr_full_install

      - build_and_cache:
          <<: *filter_only_topic
          name: pr_full_build_release
          release: true
          requires:
            - pr_full_install

      - unit_test_esm:
          <<: *filter_only_topic
          name: pr_full_test_chrome
          npm_command: "test-chrome"
          install_chrome: true
          requires:
            - pr_full_build_release

      - unit_test_esm_node:
          <<: *filter_only_topic
          name: pr_full_test_node
          requires:
            - pr_full_build_release

      - unit_test_cjs:
          <<: *filter_only_topic
          name: pr_full_test_toolings
          requires:
            - pr_full_build_release

      - e2e_test:
          <<: *filter_only_topic
          name: pr_full_e2e_hmr_vite
          path: "packages/__e2e__/2-hmr-vite"
          requires:
            - pr_full_build_release

      - e2e_test:
          <<: *filter_only_topic
          name: pr_full_e2e_router
          path: "packages/__e2e__/6-router"
          run_webpack: true
          requires:
            - pr_full_build_release

  pr_bench:
    when: << pipeline.parameters.run_pr_full >>
    jobs:
      - checkout_install_cache:
          <<: *filter_only_topic
          name: pr_bench_install

      - build_and_cache:
          <<: *filter_only_topic
          name: pr_bench_build_release
          release: true
          requires:
            - pr_bench_install

      - tacho_benchmark_prep:
          <<: *filter_only_topic
          requires:
            - pr_bench_build_release

      - tacho_benchmark:
          <<: *filter_only_topic
          name: pr_benchmark_startup
          command: npm run bench:startup10k
          requires:
            - tacho_benchmark_prep

      - tacho_benchmark:
          <<: *filter_only_topic
          name: pr_benchmark_rerender
          command: npm run bench:rerender10k
          requires:
            - tacho_benchmark_prep

  benchmarks:
    when: << pipeline.parameters.run_bench >>
    jobs:
      - checkout_install_cache:
          <<: *filter_only_topic
          name: bench_install

      - build_and_cache:
          <<: *filter_only_topic
          name: bench_build_release
          release: true
          requires:
            - bench_install

      - tacho_benchmark_prep:
          <<: *filter_only_topic
          name: bench_prep
          requires:
            - bench_build_release

      - tacho_benchmark:
          <<: *filter_only_topic
          name: bench_startup10k
          command: npm run bench:startup10k
          requires:
            - bench_prep

      - tacho_benchmark:
          <<: *filter_only_topic
          name: bench_startup10k_ce
          command: npm run bench:startup10k-ce
          requires:
            - bench_prep

      - tacho_benchmark:
          <<: *filter_only_topic
          name: bench_rerender10k
          command: npm run bench:rerender10k
          requires:
            - bench_prep

      - tacho_benchmark:
          <<: *filter_only_topic
          name: bench_rerender10k_ce
          command: npm run bench:rerender10k-ce
          requires:
            - bench_prep

      - tacho_benchmark:
          <<: *filter_only_topic
          name: bench_rerender1k_big
          command: npm run bench:rerender1k-big
          requires:
            - bench_prep

      - tacho_benchmark:
          <<: *filter_only_topic
          name: bench_startup1k_big
          command: npm run bench:startup1k-big
          requires:
            - bench_prep

      - tacho_benchmark:
          <<: *filter_only_topic
          name: bench_update1k
          command: npm run bench:update1k
          requires:
            - bench_prep

      - tacho_benchmark:
          <<: *filter_only_topic
          name: bench_repeat_keyed_expression
          command: npm run bench:repeat-expr
          requires:
            - bench_prep

      - tacho_benchmark:
          <<: *filter_only_topic
          name: bench_repeat_keyed_string
          command: npm run bench:repeat-string
          requires:
            - bench_prep

  # Runs build and tests (master)
  build_test:
    jobs:
      - check_doc_abort:
          <<: *filter_only_master
      - checkout_install_cache:
          <<: *filter_only_master
          name: checkout_install
          requires:
            - check_doc_abort
      - build_and_cache:
          <<: *filter_only_master
          name: build_release
          release: true
          requires:
            - checkout_install
      - unit_test_esm:
          <<: *filter_only_master
          name: test_chrome
          npm_command: "test-chrome"
          install_chrome: true
          requires:
            - build_release
      - unit_test_esm_node:
          <<: *filter_only_master
          name: test_node
          requires:
            - build_release
      - unit_test_cjs:
          <<: *filter_only_master
          name: test_toolings
          requires:
            - build_release
      - lint_packages:
          <<: *filter_only_master
          requires:
            - checkout_install
      - e2e_verdaccio:
          <<: *filter_only_master
          name: e2e_verdaccio_parcel_ts
          path: "test/verdaccio-apps/parcel-conventions"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_gh_issues
          path: "packages/__e2e__/1-gh-issues"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_hmr_vite
          path: "packages/__e2e__/2-hmr-vite"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_vite_wo_convention
          path: "packages/__e2e__/9-vite-wo-convention"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_hmr_webpack
          path: "packages/__e2e__/3-hmr-webpack"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_router
          path: "packages/__e2e__/6-router"
          run_webpack: true
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_router_none_history_with_hash
          path: "packages/__e2e__/10-router-none-history-with-hash"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_router_direct
          path: "packages/__e2e__/5-router-direct"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_i18n
          path: "packages/__e2e__/4-i18n"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_validation_issue_2025
          path: "packages/__e2e__/11-validation"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_type_check
          path: "packages/__e2e__/12-type-check"
          requires:
            - build_release
      - e2e_test:
          <<: *filter_only_master
          name: e2e_virtual_repeat
          path: "packages/__e2e__/8-ui-virtualization"
          requires:
            - build_release
      - tacho_benchmark_prep:
          <<: *filter_only_master
          requires:
            - build_release
      - tacho_benchmark:
          <<: *filter_only_master
          name: benchmark_startup
          command: npm run bench:startup10k
          requires:
            - tacho_benchmark_prep
      - tacho_benchmark:
          <<: *filter_only_master
          name: benchmark_startup___custom_element
          command: npm run bench:startup10k-ce
          requires:
            - tacho_benchmark_prep
      - tacho_benchmark:
          <<: *filter_only_master
          name: benchmark_rerender
          command: npm run bench:rerender10k
          requires:
            - tacho_benchmark_prep
      - tacho_benchmark:
          <<: *filter_only_master
          name: benchmark_rerender__custom_element
          command: npm run bench:rerender10k-ce
          requires:
            - tacho_benchmark_prep
      - tacho_benchmark:
          <<: *filter_only_master
          name: benchmark_rerender1k-big-template
          command: npm run bench:rerender1k-big
          requires:
            - tacho_benchmark_prep
      - tacho_benchmark:
          <<: *filter_only_master
          name: benchmark_startup1k-big-template
          command: npm run bench:startup1k-big
          requires:
            - tacho_benchmark_prep
      - tacho_benchmark:
          <<: *filter_only_master
          name: benchmark_update
          command: npm run bench:update1k
          requires:
            - tacho_benchmark_prep
      - tacho_benchmark:
          <<: *filter_only_master
          name: benchmark_repeat_keyed_expression
          command: npm run bench:repeat-expr
          requires:
            - tacho_benchmark_prep
      - tacho_benchmark:
          <<: *filter_only_master
          name: benchmark_repeat_keyed_string
          command: npm run bench:repeat-string
          requires:
            - tacho_benchmark_prep
